{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50ee704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "from glob import glob \n",
    "\n",
    "def load_data(filedata):\n",
    "\n",
    "    dataframe = pd.read_csv(\n",
    "        filedata,\n",
    "        index_col=False,\n",
    "        compression=\"zip\",\n",
    "    )\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea11806",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Paso 1 ################\n",
    "#Limpiar los datos\n",
    "def clean_data(df):\n",
    "    df_copy = df.copy()\n",
    "    current_year = 2021\n",
    "    columns_to_drop = ['Year', 'Car_Name']\n",
    "    df_copy[\"Age\"] = current_year - df_copy[\"Year\"]\n",
    "    df_copy = df_copy.drop(columns=columns_to_drop)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a937679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Paso 2 ################\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test.\n",
    "def split_data(df):\n",
    "    #X , Y\n",
    "    return df.drop(columns=[\"Present_Price\"]), df[\"Present_Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008a72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Paso 3 ################\n",
    "# Crear un pipeline para el modelo de clasificación\n",
    "def make_pipeline(x_train):\n",
    "    categorical_features=['Fuel_Type','Selling_type','Transmission']\n",
    "    numerical_features= [col for col in x_train.columns if col not in categorical_features]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(), categorical_features),\n",
    "                ('scaler',MinMaxScaler(),numerical_features),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    pipeline=Pipeline(\n",
    "            [\n",
    "                (\"preprocessor\",preprocessor),\n",
    "                ('feature_selection',SelectKBest(f_regression)),\n",
    "                ('classifier', LinearRegression())\n",
    "            ]\n",
    "        )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30826b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Paso 4 ################\n",
    "# Optimizar los hiperparametros del pipeline usando validación cruzada.\n",
    "def create_estimator(pipeline):\n",
    "    # Definición de la malla de parámetros para la búsqueda\n",
    "    param_grid = {\n",
    "    'feature_selection__k':range(1,25),\n",
    "    'classifier__fit_intercept':[True,False],\n",
    "    'classifier__positive':[True,False]\n",
    "\n",
    "}\n",
    "\n",
    "    # Configuración de GridSearchCV para la validación cruzada\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,           # Pipeline que incluye el preprocesamiento y el clasificador\n",
    "        param_grid=param_grid,        # Hiperparámetros a optimizar\n",
    "        cv=10,                        # 10 divisiones para la validación cruzada\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        refit=True, \n",
    "        verbose= 1\n",
    "    )\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601c267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Paso 5 ################\n",
    "# Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "def _create_output_directory(output_directory):\n",
    "    if os.path.exists(output_directory):\n",
    "        for file in glob(f\"{output_directory}/*\"):\n",
    "            os.remove(file)\n",
    "        os.rmdir(output_directory)\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "def _save_model(path, estimator):\n",
    "    _create_output_directory(\"files/models/\")  # Verifica que el directorio se gestione correctamente.\n",
    "\n",
    "    with gzip.open(path, \"wb\") as f:  # Abre el archivo comprimido en modo escritura binaria.\n",
    "        pickle.dump(estimator, f)  # Guarda el modelo serializado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a97834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Paso 6 ################\n",
    "# Calcule las metricas de precision, precision balanceada, recall...\n",
    "def calculate_metrics(dataset_type, y_true, y_pred):\n",
    "    \"\"\"Calculate metrics\"\"\"\n",
    "    return {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": dataset_type,\n",
    "        'r2': float(r2_score(y_true, y_pred)),\n",
    "        'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "        'mad': float(median_absolute_error(y_true, y_pred)),\n",
    "    }\n",
    "    \n",
    "\n",
    "def _run_jobs():\n",
    "    \n",
    "    data_train = load_data(\"./files/input/train_data.csv.zip\")\n",
    "    data_test = load_data(\"./files/input/test_data.csv.zip\")\n",
    "    data_train = clean_data(data_train)\n",
    "    data_test = clean_data(data_test)\n",
    "    x_train, y_train = split_data(data_train)\n",
    "    x_test, y_test = split_data(data_test)\n",
    "    pipeline = make_pipeline(x_train)\n",
    "\n",
    "    estimator = create_estimator(pipeline)\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    _save_model(\n",
    "        os.path.join(\"files/models/\", \"model.pkl.gz\"),\n",
    "        estimator,\n",
    "    )\n",
    "\n",
    "    y_test_pred = estimator.predict(x_test)\n",
    "    test_precision_metrics = calculate_metrics(\"test\", y_test, y_test_pred)\n",
    "    y_train_pred = estimator.predict(x_train)\n",
    "    train_precision_metrics = calculate_metrics(\"train\", y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    os.makedirs(\"files/output/\", exist_ok=True)\n",
    "\n",
    "    with open(\"files/output/metrics.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(json.dumps(train_precision_metrics) + \"\\n\")\n",
    "        file.write(json.dumps(test_precision_metrics) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9769f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    _run_jobs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
